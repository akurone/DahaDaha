{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kusur Azaldıkça Kalite Artar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hazırlık"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29996, ['.', 'a', 'b', 'a', 'c', 'a', '.'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gerekli kütüphaneler\n",
    "import torch\n",
    "\n",
    "# bunlar bize hep lazım\n",
    "alfabe = list('.abcçdefgğhıijklmnoöprsştuüvyz')\n",
    "harf2idx = { harf:idx for idx, harf in enumerate(alfabe) }\n",
    "idx2harf = { idx:harf for harf, idx in harf2idx.items() }\n",
    "\n",
    "# bize lazım olan işlem: bir string alıp başına ve sonuna nokta ekle\n",
    "def isle(x):\n",
    "  return ['.'] + list(x) + ['.']\n",
    "# bunu da çok kullanacağız\n",
    "def bigramGetir(x):\n",
    "  return zip(x, x[1:])\n",
    "\n",
    "# isimleri okurken işleyelim\n",
    "isimler =  list(map(lambda satir: isle(satir), open(\"./isimler.txt\", \"r\").read().splitlines()))\n",
    "len(isimler), isimler[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaldığımız Yer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.0000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = torch.ones((30, 30), dtype = torch.float)\n",
    "for isim in isimler:\n",
    "  for h1, h2 in bigramGetir(isim):\n",
    "    M[harf2idx[h1], harf2idx[h2]] += 1\n",
    "\n",
    "P = M / M.sum(dim = 1, keepdim = True)\n",
    "P.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Harfleri eşit olasılıkla dizerek elimizdekilere benzer bir şey üretmemizin mümkün olmadığına kanaat getirdik.\n",
    "- \"İsimleri oluşturan harfler hangi olasılıkla göre birbirini takip ediyor?\" sorusuna yukarıdaki kod ile cevap aradık.\n",
    "- Olasılıklara dikkat ederek çöp elde etmesek de kaliteli bir çıktı üretemedik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalite Derken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Ölçemezsek iyileştiremeyeceğimize\" göre _kalite_ istiyorsak bunu kantitatif bir şekilde ifade edebilmeliyiz. Önce sözlü ifade edelim: modelin ürettiği yeni ismin, veri setinin istatistiksel yapısına uyumu.\n",
    "\n",
    "Modelimiz \"hiçbir şey öğrenmeseydi\" her harf için 1/30 olasılığa takılı kalacaktık. Fakat aşağıdaki _abacılar_ örneğinde görüyoruz ki \"eşit ihtimalin\" ötesinde bir bilgi elde edebilmişiz. Bu isim için ne kadar bilgi öğrendiğimizi gösteren bir değer üretelim:\n",
    "\n",
    "[MLE](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation) yöntemi ile bu ismi oluşturan bigramların olasılıklarını çarparak özetleyelim. Elde ettiğimiz bu sayı 0 (en kötü) ve 1 (en iyi) arasında bir değer olacak.\n",
    "\n",
    "Burada mini çakallıklar yapıp sadece daha okunaklı bir değere ulaşmak adına `MLE`'den `NLL`'ye terfi edeceğiz:\n",
    "\n",
    "- `MLE` ile hesapladığımız değer 0-1 arasına sıkıştığı için [log](https://en.wikipedia.org/wiki/Likelihood_function#Log-likelihood)'unu alıp 0 ile -∞ arasına genişletiyoruz. Aşağıda göreceğiniz gibi değerler özünde aynı olsa da MLE gözünüzü kanatabiliyor.\n",
    "- Bu (`LL`) değerin tersini alarak temiz bir ölçü elde ediyoruz (`Negative LL`: `NLL`).\n",
    "- `NLL` değerini öğe adedi ile bölerek kullanırsak biraz daha normalleştirebiliriz, yine aynı şeyi ifade ediyor olsak da bu gösterim daha okunaklı.\n",
    "\n",
    "`NLL` bizim için bir `loss function`: 0 ise mükemmel, ne kadar büyükse o kadar kötü. Birazdan buna odaklanacağız.\n",
    "\n",
    "Bununla birlikte bir mini çakallık daha yaptık: matrisi `torch.zeroes` yerine `torch.ones` ile başlattık ki (mesela) _jj_ veri setinde olmasa da 1 kez görmüş gibi saydık ve `log(0)` sorunundan kurtulduk. Camia buna `smoothing` diyor.\n",
    "\n",
    "Bakalım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "---Öğeler:--------\n",
      "------------------\n",
      ".a: 0.1046 (03141 / 30026)\n",
      "ab: 0.0237 (00883 / 37311)\n",
      "ba: 0.4033 (02514 / 06234)\n",
      "ac: 0.0273 (01017 / 37311)\n",
      "cı: 0.2646 (01236 / 04671)\n",
      "ıl: 0.0808 (01089 / 13479)\n",
      "la: 0.2073 (03822 / 18438)\n",
      "ar: 0.1736 (06479 / 37311)\n",
      "r.: 0.2460 (04201 / 17080)\n",
      "------------------\n",
      "---Özet:----------\n",
      "------------------\n",
      "MLE: 0.00000000515\n",
      "LL :      -19.0841\n",
      "NLL:        2.1205\n"
     ]
    }
   ],
   "source": [
    "def prn(isim):\n",
    "  mle = 1.0\n",
    "  ll = 0.0\n",
    "  n = 0\n",
    "  print(f'------------------')\n",
    "  print(f'---Öğeler:--------')\n",
    "  print(f'------------------')\n",
    "  for h1, h2 in bigramGetir(isle(isim)):\n",
    "    olasilik = P[harf2idx[h1], harf2idx[h2]]\n",
    "    adet = M[harf2idx[h1], harf2idx[h2]]\n",
    "    topl = M[harf2idx[h1]].sum()\n",
    "    mle *= olasilik\n",
    "    logOl = torch.log(olasilik)\n",
    "    ll += logOl\n",
    "    n += 1\n",
    "    print(f'{h1}{h2}: {olasilik:.4f} ({adet:05.0f} / {topl:05.0f})')\n",
    "  \n",
    "  print(f'------------------')\n",
    "  print(f'---Özet:----------')\n",
    "  print(f'------------------')\n",
    "  print(f'MLE: {mle:.11f}')\n",
    "  print(f'LL :      {ll:.4f}')\n",
    "  print(f'NLL:        {-ll/n:.4f}')\n",
    "\n",
    "prn('abacılar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimiz değmişken tüm model için `NLL` hesaplayalım; belki lazım olur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "---Tümü:---\n",
      "-----------\n",
      "NLL: 2.5279\n"
     ]
    }
   ],
   "source": [
    "ll = 0.0\n",
    "n = 0\n",
    "for isim in isimler:\n",
    "  for h1, h2 in bigramGetir(isim):\n",
    "    ll += torch.log(P[harf2idx[h1], harf2idx[h2]])\n",
    "    n += 1\n",
    "\n",
    "print(f'-----------')\n",
    "print(f'---Tümü:---')\n",
    "print(f'-----------')\n",
    "print(f'NLL: {-ll/n:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_abacılar_ isminin nasıl olası olduğunu gördük; olmayası bir örnek verelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "---Öğeler:--------\n",
      "------------------\n",
      ".j: 0.0000 (00001 / 30026)\n",
      "jö: 0.0238 (00001 / 00042)\n",
      "öj: 0.0003 (00001 / 03669)\n",
      "jö: 0.0238 (00001 / 00042)\n",
      "ö.: 0.0003 (00001 / 03669)\n",
      "------------------\n",
      "---Özet:----------\n",
      "------------------\n",
      "MLE: 0.00000000000\n",
      "LL :      -34.2005\n",
      "NLL:        6.8401\n"
     ]
    }
   ],
   "source": [
    "prn('jöjö')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Özetle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kusur için bir ölçü belirledik, bunu azalttığımızda kaliteyi artıracağımızı gördük.\n",
    "- Bu ölçüye göre isimlerin ne kadar olası veya _olmayası_ olduğuna dair bir fikrimiz var artık.\n",
    "- Akla gelen en makul yöntem ile biraz ilerleme kaydettik. Harfleri üçer, dörder gruplamak bir sonraki doğal adım olarak görünebilir ama bu yaklaşımı büyük ölçekte çalıştırmak zor: 3 harflik bir bağlam oluşturduk diyelim bir anda 27000x27000 bir matrisle çalışıyor olacağız ve adetler anlamsız hale gelecek kadar küçülecek."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
