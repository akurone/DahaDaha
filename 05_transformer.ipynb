{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GbT μLM\n",
    "Generative _BARELY_ Pretrained Transformer _MICRO_ Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu seferki makalemiz [bu](https://arxiv.org/abs/1706.03762). Yaptığımız şeyleri bu safhada bu modelin en basit halini uygulayabilmek adına yaptık:\n",
    "\n",
    "![Transformer](.assets/i8.png)\n",
    "\n",
    "Modelin `encoder` yapısını gözardı edeceğiz, `decoder` içinde ise `self-attention` yapısına odaklanıyoruz (yani `cross-attension` mevhumundan bahsetmiyoruz):\n",
    "\n",
    "![Attention](.assets/i9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Scaled Dot-Product Attention\" Nedir?\n",
    "\n",
    "Çalışmamız kapsamında bu yapı ne iş görüyor (sadece dikkat mekanizması açısından önemli adımlara) adım adım bakalım:\n",
    "\n",
    "1. Harfler (çalışmamızdaki _token_) için bir _embedding_ oluştur.\n",
    "1. İstenen bağlam boyutu kadar (çalışmamızda en uzun kelime boyu +1) pozisyonlar için bir _embedding_ oluştur.\n",
    "1. Bu iki _embedding_ değerini topla ve _girdiyi_ oluştur.\n",
    "1. Bu girdi ile 3 doğrusal katman oluştur:\n",
    "   - **q**: sorgu; iki harf benzer sorgulara sahipse birbirlerini ilgilendirirler\n",
    "   - **k**: anahtar; her harfin kendini tanıtan bilgi\n",
    "   - **v**: değer; her harfin bir diğerine aktaracağı bilgi. Sorgu ve anahtar bilgilerinin çarpımı o değerden ne kadar faydalanacağını belirliyor.\n",
    "1. `q x transpose(k)` hesapla, normalize et.\n",
    "1. Maske uygula (ve sonra normalize et): bağlam içindeki tüm harfler birbirini görürse \"bir sonraki harfi tahmin etme\" görevi anlamsız olacak.\n",
    "1. Sonucu `v` ile çarparak _çıktıyı_ elde et.\n",
    "\n",
    "Elde ettiğimiz çıktı, her harfin kendinden önceki harflerle kurduğu bağ üzerinden elde ettiği bir bilgi. Bu bilgi, şimdiye kadar kullandığımız \"bağlamda şu 3-5 harf varsa bir sonraki harf şu olur\" yaklaşımından çok daha güçlü: mesela model adını koyamasa da ünlü uyumu kurallarını keşfedebilir durumda. Bu bilgiyi elde ettikten sonra yeni maceralar peşinde koşmuyoruz aslında; bunu eldeki araçlar vasıtasıyla kullanıp daha tutarlı \"uyduran\" bir modele kavuşuyoruz.\n",
    "\n",
    "Tabi elde ettiğimiz bu bilgi ile daha karmaşık yapılardan vazgeçebilir hale geliyoruz, dolayısıyla modelin eğitilebilirliği (zaman maliyeti açısından) kolaylaşıyor. Bu arada işlemlerin GPU üzerinde paralel olarak çalıştırılabilmesi de bu hızlı eğitimin önünü açan diğer kritik bileşen. Bunlar olmasaydı bugün transformer tarihteki vasat tercüme makalelerinden birinde geçen bir kavram olacaktı sadece.\n",
    "\n",
    "En basit hali bir işe yaramasa da kod olarak burada bir dursun:\n",
    "\n",
    "```py\n",
    "BLOK, EMBED = 31, 60 # bunlar modelin \"hiper\" parametreleri\n",
    "maske = torch.tril(torch.ones(BLOK, BLOK))\n",
    "girdi = torch.randn(BLOK, EMBED) # bu dışarıdan gelecek (x), çalışsın diye öylesine bir değer verdik\n",
    "\n",
    "# aslında bu katmanları bir kez oluşturup forward pass içinde mevcutları kullanmamız lazım;\n",
    "# saçma olsa da ne olduğunu görmek adına böyle:\n",
    "q = nn.Linear(EMBED, EMBED)(girdi)\n",
    "k = nn.Linear(EMBED, EMBED)(girdi)\n",
    "v = nn.Linear(EMBED, EMBED)(girdi)\n",
    "\n",
    "carpim = q @ k.transpose(-2, -1)\n",
    "maskeli = carpim.masked_fill(maske == 0, float('-inf'))\n",
    "\n",
    "dikkat = F.softmax(maskeli, dim=-1)\n",
    "\n",
    "cikti = dikkat @ v # (y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hazırlık"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29996,\n",
       " 30,\n",
       " 30,\n",
       " (tensor([ 0,  1,  2,  1,  3, 11, 15,  1, 21,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       "  tensor([ 1,  2,  1,  3, 11, 15,  1, 21,  0, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "          -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "alfabe = list('.abcçdefgğhıijklmnoöprsştuüvyz')\n",
    "harf2idx = { harf:idx for idx, harf in enumerate(alfabe) }\n",
    "idx2harf = { idx:harf for harf, idx in harf2idx.items() }\n",
    "\n",
    "isimler = open(\"./isimler.txt\", \"r\").read().splitlines()\n",
    "maxUzunluk = max([len(isim) for isim in isimler])\n",
    "\n",
    "def isle(isim):\n",
    "  enc, ln = torch.tensor([harf2idx[h] for h in isim], dtype=torch.long), len(isim)\n",
    "  x, y = torch.zeros(maxUzunluk + 1, dtype=torch.long), torch.zeros(maxUzunluk + 1, dtype=torch.long)\n",
    "  x[1:1+ln] = enc\n",
    "  y[:ln] = enc\n",
    "  y[ln+1:] = -1\n",
    "  return x, y\n",
    "\n",
    "def xyOlustur(isimler):\n",
    "  X, Y = [], []\n",
    "  for isim in isimler:\n",
    "    x, y = isle(isim)\n",
    "    X.append(x) ; Y.append(y)\n",
    "  X, Y = torch.stack(X), torch.stack(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "@torch.inference_mode()\n",
    "@torch.no_grad()\n",
    "def ornekUret(model, adet):\n",
    "  model.eval()\n",
    "  n_blk, ornekler = model.block_size, torch.zeros(adet, 1, dtype=torch.long)\n",
    "  def kirp(x):\n",
    "    y = x[1:].tolist() ; y = y[:y.index(0) if 0 in y else len(y)] ; return y # 0..0 arası lazım sadece, sonda 0 yoksa hepsi gelecek\n",
    "  def metneCevir(x):\n",
    "    return ''.join(idx2harf[h] for h in x)\n",
    "  for _ in range(n_blk - 1):\n",
    "    logits, _ = model(ornekler if ornekler.size(1) <= n_blk else ornekler[:, -n_blk:])\n",
    "    siradaki = torch.multinomial(F.softmax(logits[:, -1, :], dim = -1), num_samples = 1)\n",
    "    ornekler = torch.cat((ornekler, siradaki), dim = 1)\n",
    "  model.train()\n",
    "  return map(lambda x: metneCevir(kirp(x)), ornekler)\n",
    "\n",
    "@torch.inference_mode()\n",
    "@torch.no_grad()\n",
    "def lossHesapla(model, X, Y):\n",
    "  model.eval()\n",
    "  _, loss = model(X, Y)\n",
    "  model.train()\n",
    "  return loss\n",
    "\n",
    "n_alfabe = len(alfabe)\n",
    "n_isim = len(isimler)\n",
    "\n",
    "n_isim, n_alfabe, maxUzunluk, isle('abacılar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri Kümeleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([29996, 31]) torch.Size([29996, 31])\n",
      "torch.Size([23996, 31]) torch.Size([23996, 31])\n"
     ]
    }
   ],
   "source": [
    "tumX, tumY = xyOlustur(isimler)\n",
    "random.seed(5) ; karisik = random.sample(isimler, k = int(0.8 * n_isim))\n",
    "trnX, trnY = xyOlustur(karisik)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soyutlamalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------------------------\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "\n",
    "  def __init__(self, config):\n",
    "    super().__init__() ; assert config.n_embd % config.n_head == 0\n",
    "    self.qkv = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "    self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "    self.register_buffer(\"bias\", torch.tril(torch.ones(1, 1, config.block_size, config.block_size)))\n",
    "    self.n_head = config.n_head\n",
    "    self.n_embd = config.n_embd\n",
    "\n",
    "  def forward(self, x):\n",
    "    B, T, C = x.size() # BATCH, TIME = BLOCK, CHANNELS = N_EMBD\n",
    "\n",
    "    q, k ,v  = self.qkv(x).split(self.n_embd, dim=2)\n",
    "    k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "    q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "    v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "\n",
    "    att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "    att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
    "    att = F.softmax(att, dim=-1) # (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "\n",
    "    y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "    y = self.c_proj(y.transpose(1, 2).contiguous().view(B, T, C))\n",
    "    return y # (B, T, C)\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Block(nn.Module):\n",
    "\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.ln_1 = nn.LayerNorm(config.n_embd)\n",
    "    self.attn = MultiHeadSelfAttention(config)\n",
    "    self.ln_2 = nn.LayerNorm(config.n_embd)\n",
    "    self.mlp = nn.ModuleDict(dict(\n",
    "      c_fc  = nn.Linear(config.n_embd, 4 * config.n_embd),\n",
    "      c_proj  = nn.Linear(4 * config.n_embd, config.n_embd),\n",
    "      act   = nn.GELU(),\n",
    "    ))\n",
    "    m = self.mlp\n",
    "    self.mlpf = lambda x: m.c_proj(m.act(m.c_fc(x))) # MLP forward\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x + self.attn(self.ln_1(x))\n",
    "    x = x + self.mlpf(self.ln_2(x))\n",
    "    return x\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.block_size = config.block_size\n",
    "\n",
    "    self.transformer = nn.ModuleDict(dict(\n",
    "      wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
    "      wpe = nn.Embedding(config.block_size, config.n_embd),\n",
    "      h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "      ln_f = nn.LayerNorm(config.n_embd),\n",
    "    ))\n",
    "    self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "\n",
    "  def forward(self, idx, targets=None):\n",
    "    _, T = idx.size() ; assert T <= self.block_size\n",
    "\n",
    "    # x = token embeddings (B, T, C) + position embeddings (1, T, C)\n",
    "    x = self.transformer.wte(idx) + self.transformer.wpe(torch.arange(0, T, dtype=torch.long).unsqueeze(0))\n",
    "    for block in self.transformer.h:\n",
    "      x = block(x)\n",
    "    x = self.transformer.ln_f(x)\n",
    "    logits = self.lm_head(x)\n",
    "    loss = None if targets is None else F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
    "\n",
    "    return logits, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205888\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(5)\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "  block_size: int = maxUzunluk + 1\n",
    "  vocab_size: int = n_alfabe\n",
    "  n_layer: int = 4\n",
    "  n_head: int = 4\n",
    "  n_embd: int = n_head * 16\n",
    "\n",
    "cfg = ModelConfig()\n",
    "model = Transformer(cfg)\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eğitim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.601732015609741\n",
      "2.0923452377319336\n",
      "1.914368987083435\n",
      "1.914691686630249\n",
      "--------------------\n",
      "trn: 1.5682162046432495 (3513)\n",
      "tum: 1.8509806394577026\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(5)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 5e-4, weight_decay = 0.01, betas = (0.9, 0.99), eps = 1e-8)\n",
    "enIyiDurum, enIyiLoss, enIyi = None, None, 0\n",
    "\n",
    "for i in range(4000):\n",
    "  bat = torch.randint(0, trnX.shape[0], (16,))\n",
    "  _, loss = model(trnX[bat], trnY[bat])\n",
    "  model.zero_grad(set_to_none = True)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  if enIyiLoss is None or loss < enIyiLoss:\n",
    "    enIyiLoss, enIyiDurum, enIyi = loss, model.state_dict(), i\n",
    "  if i % 1000 == 0: \n",
    "    print(loss.item())\n",
    "\n",
    "model.load_state_dict(enIyiDurum)\n",
    "print('-'*20)\n",
    "print(f'trn: {enIyiLoss.item()} ({enIyi})')\n",
    "print(f'tum: {lossHesapla(model, tumX, tumY).item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sonuç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "3 örnek eğitimde görüldü:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "karandere\n",
      "camili\n",
      "yaylıca\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "1 örnek eğitimde görülmedi:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "celi\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "46 örnek yeni:\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "karaeşi\n",
      "çağşık\n",
      "belersanlık\n",
      "akşayamba\n",
      "karadımğırı\n",
      "tokurlar\n",
      "çatırekki\n",
      "kayupkırganı\n",
      "elbeyoğlu\n",
      "çivendiğ\n",
      "datalık\n",
      "çayhallı\n",
      "şahrif\n",
      "karımalan\n",
      "kouluderesi\n",
      "taltar\n",
      "çanakdırca\n",
      "yaycıgöze\n",
      "ekingüney\n",
      "kahaçten\n",
      "mizileliler\n",
      "mediroğlu\n",
      "etekuyu\n",
      "köpret\n",
      "kalmaklı\n",
      "bozuri\n",
      "dakılıkışcınlı\n",
      "bekdivançır\n",
      "yivriserişlen\n",
      "yamaserli\n",
      "korumuşağı\n",
      "soğarbayır\n",
      "muslurhalli\n",
      "havumler\n",
      "elmaydalak\n",
      "ekvanut\n",
      "sevece\n",
      "şicfiroğlu\n",
      "düngimbi\n",
      "elaköy\n",
      "erekay\n",
      "karabedi\n",
      "ebsertepe\n",
      "yukarıaç\n",
      "balüyereci\n",
      "çörükyus\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(5)\n",
    "\n",
    "inTrn, inTum, yeni = [], [], []\n",
    "for ornek in ornekUret(model, 50):\n",
    "  if ornek in karisik:\n",
    "    inTrn.append(ornek)\n",
    "  elif ornek in isimler:\n",
    "    inTum.append(ornek)\n",
    "  else:\n",
    "    yeni.append(ornek)\n",
    "\n",
    "for lst, yer in [(inTrn, 'eğitimde görüldü'), (inTum, 'eğitimde görülmedi'), (yeni, 'yeni')]:\n",
    "  if len(lst) == 0: continue\n",
    "  print('-*'*15)\n",
    "  print(f\"{len(lst)} örnek {yer}:\")\n",
    "  print('*-'*15)\n",
    "  for ornek in lst:\n",
    "    print(ornek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelin en iyi durumunu kaydettik, incelemek için aşağıdaki satırı açıp çalıştırmak yeterli\n",
    "# enIyiDurum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
