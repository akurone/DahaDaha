{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basit bir Yapay Sinir Ağı (NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hazırlık"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29996"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gerekli kütüphaneler\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# bunlar bize hep lazım\n",
    "alfabe = list('.abcçdefgğhıijklmnoöprsştuüvyz')\n",
    "harf2idx = { harf:idx for idx, harf in enumerate(alfabe) }\n",
    "idx2harf = { idx:harf for harf, idx in harf2idx.items() }\n",
    "\n",
    "# bize lazım olan işlem: bir string alıp başına ve sonuna nokta ekle\n",
    "def isle(x):\n",
    "  return ['.'] + list(x) + ['.']\n",
    "# bunu da çok kullanacağız\n",
    "def bigramGetir(x):\n",
    "  return zip(x, x[1:])\n",
    "\n",
    "# isimleri okurken işleyelim\n",
    "isimler =  list(map(lambda isim: isle(isim), open(\"./isimler.txt\", \"r\").read().splitlines()))\n",
    "len(isimler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Örnekle Başlayalım"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olabilecek en basit NN yapısını elde etmeye çalışacağız ki bu bize bigram model ile neredeyse aynı çıktıları üretecek: önyargı ve aktivasyon bileşenleri olmayacak, tek girdi (bu harf) alacak ve peşinde olduğumuz çıktıyı -sıradaki harf- üretecek.\n",
    "\n",
    "Artık bigram oluşturmayacağız fakat modeli \"x görürsen y üret\" şeklinde eğiteceğimiz için harf çiftlerini bu sefer x (girdi) ve y (beklenen çıktı yani _label_) olarak gruplayacağız.\n",
    "\n",
    "_abacılar_ örneğimizi bu açıdan inceleyelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = . (00) -> Y = a (01)\n",
      "X = a (01) -> Y = b (02)\n",
      "X = b (02) -> Y = a (01)\n",
      "X = a (01) -> Y = c (03)\n",
      "X = c (03) -> Y = ı (11)\n",
      "X = ı (11) -> Y = l (15)\n",
      "X = l (15) -> Y = a (01)\n",
      "X = a (01) -> Y = r (21)\n",
      "X = r (21) -> Y = . (00)\n",
      "[0, 1, 2, 1, 3, 11, 15, 1, 21]\n",
      "[1, 2, 1, 3, 11, 15, 1, 21, 0]\n"
     ]
    }
   ],
   "source": [
    "ornekX, ornekY = [], []\n",
    "\n",
    "for h1, h2 in bigramGetir(isle('abacılar')):\n",
    "  ornekX.append(harf2idx[h1]) ; ornekY.append(harf2idx[h2])\n",
    "  print(f'X = {h1} ({harf2idx[h1]:02}) -> Y = {h2} ({harf2idx[h2]:02})')\n",
    "\n",
    "print(ornekX) ; print(ornekY)\n",
    "\n",
    "ornekAdet = len(ornekX)\n",
    "ornekAdetTens, ornekYTens = torch.arange(ornekAdet), torch.tensor(ornekY)\n",
    "\n",
    "# aşağıdaki kod örneğe dair durumu yazdırmak için:\n",
    "def prnOrnek(P):\n",
    "  loss = torch.zeros(ornekAdet)\n",
    "  for i in range(ornekAdet):\n",
    "    xi, yi = ornekX[i], ornekY[i]\n",
    "    p = P[i, yi] ; nll = -torch.log(p)\n",
    "    print(f'({idx2harf[xi]}:{xi:02}) -> ({idx2harf[yi]}:{yi:02}) p: {p.item():.4f} NLL: {nll.item():.4f}')\n",
    "    loss[i] = nll\n",
    "  \n",
    "  print('=========')\n",
    "  print(f'NLL: {loss.mean().item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tek girdimiz var ama tek ağırlığa sahip olmak zorunda değiliz: Elimizde harfi ifade eden 1-30 arası bir sayı var. Bu sayıyı 30 bitlik bir diziye çevirip nöronu buna göre oluşturduğumuzda tek ağırlık üzerinde cambazlık yapmak yerine 30 farklı ağırlıkla daha hassas bir yapı elde edebiliriz. Yani tek girdiyi 30 parçaya böldük. Nöronumuz w1x1+...+w30x30 şekline büründü (ya da 30 tane tek girdisi olan nörünumuz var diyebilir miyiz?). Bunu uygulamak için camia'nın sevdiği `one_hot` fonksiyonunu kullanacağız:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 30])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ornekXEncoded = F.one_hot(torch.tensor(ornekX), num_classes = 30).float()\n",
    "plt.imshow(ornekXEncoded)\n",
    "ornekXEncoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aşağıda rastgele doldurduğumuz ağırlıklar (ve bir önyargı olmayacağı için esasen nöronlar) mevcut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(5)\n",
    "ornekW = torch.randn((30, 30), requires_grad = True) # requires_grad = True ifadesine dikkat!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matris çarpımı (@) ile tüm girdileri bir seferde paralel olarak nöronlara veriyoruz. Takip eden iki işlem ise (birlikte) `softmax`. Burada yaptığımız aslında bigram modelimizdeki M ve P'nin muadillerini oluşturmak. Tabii bu bizim saydığımız adetler yerine rastgele rakamlardan oluşuyor. Bu haliyle bir de `loss` hesaplayıp detayları yazdıralım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(.:00) -> (a:01) p: 0.0283 NLL: 3.5640\n",
      "(a:01) -> (b:02) p: 0.0138 NLL: 4.2799\n",
      "(b:02) -> (a:01) p: 0.0410 NLL: 3.1946\n",
      "(a:01) -> (c:03) p: 0.0086 NLL: 4.7506\n",
      "(c:03) -> (ı:11) p: 0.0159 NLL: 4.1416\n",
      "(ı:11) -> (l:15) p: 0.0090 NLL: 4.7111\n",
      "(l:15) -> (a:01) p: 0.0296 NLL: 3.5190\n",
      "(a:01) -> (r:21) p: 0.0535 NLL: 2.9284\n",
      "(r:21) -> (.:00) p: 0.0437 NLL: 3.1296\n",
      "=========\n",
      "NLL: 3.8021\n"
     ]
    }
   ],
   "source": [
    "logits = ornekXEncoded @ ornekW # \"logit\": bu işlemin sonucundaki tek öğenin literatürdeki ismi, ve buradaki çoğul hali\n",
    "# softmax: daha sonra bunun yerine bunu kullanacağız: https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html\n",
    "sankiM = torch.exp(logits)\n",
    "sankiP = sankiM / sankiM.sum(dim = 1, keepdim = True)\n",
    "\n",
    "prnOrnek(sankiP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Örnek ismimiz üzerinden modelimizi eğitelim:\n",
    "\n",
    "- önce yukarıda açıkça yazdığımız işlemi 1 satırda yapıyoruz. `ornekW` değişkenini oluştururken `requires_grad = True` dediğimiz için bundan türeyen tüm değişkenlerimizde de `grad` hesaplanabilir olacak.\n",
    "- yine tek satırda loss hesaplıyoruz: her bir satırdaki `ornekY` pozisyonundaki değerleri alıp -log sonrasında ortalamaya tabi tutuyoruz.\n",
    "- _forward pass_ yaptık!\n",
    "- _backward pass_ işlemini de `torch` kütüphanesinin yardımıyla tek satırda yapacağız: `loss.backward()` (`loss` `ornekW` değişkeninden türüyor, dikkat!)\n",
    "- fakat önce `grad` değerlerini temizliyoruz (kütüphane `grad` için hesapladığı değeri mevcut değere eklediği için bunu yapıyoruz).\n",
    "- artık tek yapmamız gereken ağırlıkları güncelleyip modeli daha iyi bir hale getirmek: burada hesaplanan `grad` değerlerini belli bir katsayı (`learning rate`) ile ağırlıklara ekliyoruz/çıkarıyoruz. Bu katsayı büyüdükçe model daha hızlı istenen noktaya gelebilir ama bu noktayı geçip hızla istenen noktadan öteye de gidebilir. Bir sonraki safhada bunu nasıl optimize edebiliriz bakacağız.\n",
    "\n",
    " Nasıl hızla `overfit` olduğuna dikkat edin. Ne kadar uğraşsak bile `loss = 0` olmayacak, peki neden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(.:00) -> (a:01) p: 0.9918 NLL: 0.0082\n",
      "(a:01) -> (b:02) p: 0.5110 NLL: 0.6714\n",
      "(b:02) -> (a:01) p: 0.9917 NLL: 0.0083\n",
      "(a:01) -> (c:03) p: 0.3015 NLL: 1.1989\n",
      "(c:03) -> (ı:11) p: 0.9916 NLL: 0.0084\n",
      "(ı:11) -> (l:15) p: 0.9916 NLL: 0.0085\n",
      "(l:15) -> (a:01) p: 0.9916 NLL: 0.0084\n",
      "(a:01) -> (r:21) p: 0.1801 NLL: 1.7142\n",
      "(r:21) -> (.:00) p: 0.9917 NLL: 0.0084\n",
      "=========\n",
      "NLL: 0.4039\n"
     ]
    }
   ],
   "source": [
    "# \"forward pass\"\n",
    "sankiP = torch.softmax(ornekXEncoded @ ornekW, dim = 1)\n",
    "loss = -sankiP[ornekAdetTens, ornekYTens].log().mean()\n",
    "\n",
    "# \"backward pass\"\n",
    "ornekW.grad = None # bunu yapmazsak grad değerleri birikir!!\n",
    "loss.backward()\n",
    "\n",
    "# update\n",
    "ornekW.data += -20 * ornekW.grad # LR değerini afaki büyük, ama şimdilik bizim için önemli değil.\n",
    "\n",
    "prnOrnek(sankiP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tüm Veri Seti ile Eğitim Yapalım"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hazırlayalım"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temelde yukarıdaki örnek için yaptıklarımızı tüm veri üzerinde yapıyoruz. Biraz `python` öğrenmek adına farklı denemeler yaptım burada:\n",
    "\n",
    "- X ve Y değerlerini ayırmak için gereken döngüleri _fonksiyonel_ ifadeler arkasına gizledim; bu önceki yöntemden daha mı iyi çalışır?\n",
    "- `tuple` bir nimet :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "282166"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(5)\n",
    "\n",
    "# her isim için bigramları alıp harften sıraya dön; x ve y olarak ayır:\n",
    "tumu = zip(*[(harf2idx[h1], harf2idx[h2]) for isim in isimler for h1, h2 in bigramGetir(isim)])\n",
    "tumX, tumY = torch.tensor(list(next(tumu))), torch.tensor(list(next(tumu)))\n",
    "\n",
    "tumAdet = tumX.nelement()\n",
    "tumX = F.one_hot(tumX, num_classes = 30).float()\n",
    "tumAdetTens = torch.arange(tumAdet)\n",
    "\n",
    "W = torch.randn((30, 30), requires_grad = True)\n",
    "tumAdet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eğitelim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tek örnek için yaptığımız işlemden farklı olarak sadece `loss` değerimizi zenginleştirdik: model kusuru azaltmaya odaklanırken ağırlık değerlerini gelen örneklere göre çok fazla optimize etsin istemiyoruz; dolayısı ile ağırlıkların 0'dan uzaklaşmasını (yani duruma göre çok özel değerlere konsantre olmalarını) istemediğimizi ifadenin içine ekledik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8994319438934326\n",
      "3.4028913974761963\n",
      "3.144059419631958\n",
      "2.992974042892456\n",
      "2.8981075286865234\n",
      "2.834346294403076\n",
      "2.7896625995635986\n",
      "2.756298780441284\n",
      "2.730377197265625\n",
      "2.709571599960327\n",
      "2.692500114440918\n",
      "2.6782171726226807\n",
      "2.666097640991211\n",
      "2.655687093734741\n",
      "2.6466643810272217\n",
      "2.6387829780578613\n",
      "2.6318585872650146\n",
      "2.6257452964782715\n",
      "2.6203267574310303\n",
      "2.615508794784546\n",
      "2.611213445663452\n",
      "2.6073741912841797\n",
      "2.6039347648620605\n",
      "2.600843667984009\n",
      "2.5980582237243652\n"
     ]
    }
   ],
   "source": [
    "# \"gradient descent\"\n",
    "for k in range(25):\n",
    "  # forward pass\n",
    "  P = torch.softmax(tumX @ W, dim = 1)\n",
    "  nll = -P[tumAdetTens, tumY].log().mean()\n",
    "  reg = 0.01 * (W**2).mean() # W değerleri büyürse artık loss da büyüyecek\n",
    "  loss = nll + reg\n",
    "  print(loss.item())\n",
    "\n",
    "  # backward pass\n",
    "  W.grad = None\n",
    "  loss.backward()\n",
    "\n",
    "  # update\n",
    "  W.data += -90 * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sonuç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".kadur.\n",
      ".ç.\n",
      ".mavardu.\n",
      ".ü.\n",
      ".tenali.\n",
      ".megükeritenaem.\n",
      ".ghasıkılı.\n",
      ".klar.\n",
      ".derı.\n",
      ".gücıkçveköçdinzlı.\n",
      ".cınakari.\n",
      ".kla.\n",
      ".ıcıçıcateyn.\n",
      ".atucpa.\n",
      ".ti.\n",
      ".koükpene.\n",
      ".yullefpımalfğındirgöemanopradoğı.\n",
      ".at.\n",
      ".k.\n",
      ".kasin.\n",
      ".bukçvan.\n",
      ".beyırı.\n",
      ".ambelenr.\n",
      ".t.\n",
      ".hay.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(5)\n",
    "for i in range(25):\n",
    "  ornek = ['.'] ; idx = 0\n",
    "  while True:\n",
    "    p = torch.softmax(F.one_hot(torch.tensor([idx]), num_classes = 30).float() @ W, dim = 1)\n",
    "    idx = torch.multinomial(p, num_samples = 1, replacement = True).item()\n",
    "    ornek.append(idx2harf[idx])\n",
    "    if idx == 0:\n",
    "      break\n",
    "  print(''.join(ornek))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
